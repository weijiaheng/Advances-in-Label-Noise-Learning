# Learning-with-Noisy-Labels

    A curated list of most recent papers & codes in Learning with Noisy Labels

---

- Content
  - [Papers & Code in 2021](#papers--code-in-2021)
    - [ICLR 2021](#ICLR-2021)
    - [CVPR 2021](#CVPR-2021)
    - [AISTATS 2021](#AISTATS-2021)
    - [AAAI 2021](#AAAI-2021)
    - [ArXiv 2021](#ArXiv-2021)
  - [Papers & Code in 2020](#papers--code-in-2020)
    - [ICML 2020](#ICML-2020)
    - [ICLR 2020](#ICLR-2020)
    - [Nips 2020](#Nips-2020)
    - [AAAI 2020](#AAAI-2020)
    - [CVPR 2020](#CVPR-2020)
    - [ECCV 2020](#ECCV-2020)
    - [ArXiv 2020](#ArXiv-2020)
---

## Papers & Code in 2021

This repo focus on papers after 2019, for previous works, please refer to (https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise).

### ICLR 2021
Conference date: May 3, 2021 -- May 7, 2021

* [[**UCSC REAL Lab**]](https://github.com/UCSC-REAL) When Optimizing f-Divergence is Robust with Label Noise. [[Paper]](https://openreview.net/pdf?id=WesiCoRVQ15)[[Code]](https://github.com/weijiaheng/Robust-f-divergence-measures) 
  - Poster Session 3: May 3, 2021, 5 p.m. -- May 3, 2021, 7 p.m. (PDT)
* [[**UCSC REAL Lab**]](https://github.com/UCSC-REAL) Learning with Instance-Dependent Label Noise: A Sample Sieve Approach. [[Paper]](https://openreview.net/pdf?id=2VXyy9mIyU3)[[Code]](https://github.com/haochenglouis/cores) 
  - Poster Session 9: May 5, 2021, 5 p.m. -- May 5, 2021, 7 p.m. (PDT)
* Noise against noise: stochastic label noise helps combat inherent label noise. [[Paper]](https://openreview.net/pdf?id=80FMcTSZ6J0)[[Code]](https://github.com/chenpf1025/SLN)
  - Poster Session 1: May 3, 2021, 1 a.m. -- May 3, 2021, 3 a.m. (PDT)
* Learning with Feature-Dependent Label Noise: A Progressive Approach. [[Paper]](https://openreview.net/pdf?id=ZPa2SyGcbwh)[[Code]](https://github.com/pxiangwu/PLC)
  - Poster Session 9: May 5, 2021, 5 p.m. -- May 5, 2021, 7 p.m. (PDT)
* Robust early-learning: Hindering the memorization of noisy labels. [[Paper]](https://openreview.net/pdf?id=Eql5b1_hTE4)[[Code]](https://github.com/xiaoboxia/CDR)
  - Poster Session 11: May 6, 2021, 9 a.m. -- May 6, 2021, 11 a.m. (PDT)
* Robust Curriculum Learning: from clean label detection to noisy label self-correction. [[Paper]](https://openreview.net/pdf?id=lmTWnm3coJJ)
  - Poster Session 3: May 3, 2021, 5 p.m. -- May 3, 2021, 7 p.m. (PDT)
* How Does Mixup Help With Robustness and Generalization? [[Paper]](https://openreview.net/pdf?id=8yKEo06dKNo)
  - Poster Session 8: May 5, 2021, 9 a.m. -- May 5, 2021, 11 a.m. (PDT)
* Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. [[Paper]](https://openreview.net/pdf?id=rC8sJ4i6kaH)
  - Poster Session 12: May 6, 2021, 5 p.m. -- May 6, 2021, 7 p.m. (PDT)
-----
### CVPR 2021
Conference date: Jun 19, 2021 -- Jun 25, 2021

* [[**UCSC REAL Lab**]](https://github.com/UCSC-REAL) A Second-Order Approach to Learning with Instance-Dependent Label Noise. [[Paper]](https://arxiv.org/abs/2012.11854)[[Code]](https://github.com/UCSC-REAL/CAL)
* Improving Unsupervised Image Clustering With Robust Learning. [[Paper]](https://arxiv.org/abs/2012.11150)
* Multi-Objective Interpolation Training for Robustness to Label Noise. [[Paper]](https://arxiv.org/abs/2012.04462)[[Code]](https://git.io/JI40X)
* Noise-resistant Deep Metric Learning with Ranking-based Instance Selection. [[Paper]](https://arxiv.org/abs/2103.16047)[[Code]](https://github.com/alibaba-edu/Ranking-based-Instance-Selection)
* Augmentation Strategies for Learning with Noisy Labels. [[Paper]](https://arxiv.org/abs/2103.02130)[[Code]](https://github.com/KentoNishi/Augmentation-for-LNL)
* Jo-SRC: A Contrastive Approach for Combating Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.13029.pdf)[[Code]](https://github.com/NUST-Machine-Intelligence-Laboratory/Jo-SRC)
* Multi-Objective Interpolation Training for Robustness to Label Noise. [[Paper]](https://arxiv.org/abs/2012.04462)[[Code]](https://github.com/DiegoOrtego/LabelNoiseMOIT)
* AutoDO: Robust AutoAugment for Biased Data with Label Noise via Scalable Probabilistic Implicit Differentiation. [[Paper]](https://arxiv.org/abs/2103.05863)[[Code]](https://github.com/gudovskiy/autodo)
* Meta Pseudo Labels. [[Paper]](https://arxiv.org/pdf/2003.10580.pdf)[[Code]](https://github.com/google-research/google-research/tree/master/meta_pseudo_labels)
* All Labels Are Not Created Equal: Enhancing Semi-supervision via Label Grouping and Co-training. [[Paper]](https://arxiv.org/abs/2104.05248)[[Code]](https://github.com/islam-nassar/semco)
* SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised Classification. [[Paper]](https://arxiv.org/abs/2103.16725)[[Code]](https://github.com/zijian-hu/SimPLE)
-----
### AISTATS 2021
Conference date: Apr 13, 2021 -- Apr 15, 2021

* Collaborative Classification from Noisy Labels. [[Paper]](http://proceedings.mlr.press/v130/maystre21a.html)
* Linear Models are Robust Optimal Under Strategic Behavior. [[Paper]](http://proceedings.mlr.press/v130/tang21a.html)
-----
### AAAI 2021
* Beyond Class-Conditional Assumption: A Primary Attempt to Combat Instance-Dependent Label Noise. [[Paper]](https://arxiv.org/abs/2012.05458)[[Code]](https://github.com/chenpf1025/IDN)
* Learning to Purify Noisy Labels via Meta Soft Label Corrector. [[Paper]](https://arxiv.org/abs/2008.00627)[[Code]](https://github.com/WuYichen-97/Learning-to-Purify-Noisy-Labels-via-Meta-Soft-Label-Corrector)
* Robustness of Accuracy Metric and its Inspirations in Learning with Noisy Labels. [[Paper]](https://arxiv.org/abs/2012.04193)[[Code]](https://github.com/chenpf1025/RobustnessAccuracy)
* Learning from Noisy Labels with Complementary Loss Functions. [[Paper]](http://palm.seu.edu.cn/zhangml/files/AAAI'21a.pdf)[[Code]](https://github.com/dengbaowang/CompLossForNoisyLabels)
* Analysing the Noise Model Error for Realistic Noisy Label Data. [[Paper]](https://arxiv.org/abs/2101.09763)[[Code]](https://github.com/uds-lsv/noise-estimation)
* Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model. [[Paper]](https://niug1984.github.io/paper/wang_aaai21.pdf)
* Learning with Group Noise. [[Paper]](https://gcatnjust.github.io/ChenGong/paper/wang_aaai21_2.pdf)
* Meta Label Correction for Noisy Label Learning. [[Paper]](https://www.microsoft.com/en-us/research/publication/meta-label-correction-for-noisy-label-learning/)
-----
### ArXiv 2021
* [[**UCSC REAL Lab**]](https://github.com/UCSC-REAL) The importance of understanding instance-level noisy labels. [[Paper]](https://arxiv.org/pdf/2102.05336.pdf)
* [[**UCSC REAL Lab**]](https://github.com/UCSC-REAL) Clusterability as an Alternative to Anchor Points When Learning with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2102.05291.pdf)[[Code]](https://github.com/zwzhu-d/HOC)
* A Theoretical Analysis of Learning with Noisily Labeled Data. [[Paper]](https://arxiv.org/abs/2104.04114)
* A Survey of Label-noise Representation Learning: Past, Present and Future. [[Paper]](https://arxiv.org/pdf/2011.04406.pdf)
* Learning Noise Transition Matrix from Only Noisy Labels via Total Variation Regularization. [[Paper]](https://arxiv.org/pdf/2102.02414.pdf)[[Code]](https://github.com/YivanZhang/lio)
* Noisy-Labeled NER with Confidence Estimation. [[Paper]](https://arxiv.org/pdf/2104.04318.pdf)[[Code]](https://github.com/liukun95/Noisy-NER-Confidence-Estimation)
* Study Group Learning: Improving Retinal Vessel Segmentation Trained with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.03451.pdf)[[Code]](https://github.com/SHI-Labs/SGL-Retinal-Vessel-Segmentation)
* Contrast to Divide: Self-Supervised Pre-Training for Learning with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.13646.pdf)[[Code]](https://github.com/ContrastToDivide/C2D)
* Exponentiated Gradient Reweighting for Robust Training Under Label Noise and Beyond. [[Paper]](https://arxiv.org/pdf/2104.01493.pdf)
* Understanding the Interaction of Adversarial Training with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2102.03482.pdf)
* Learning from Noisy Labels via Dynamic Loss Thresholding. [[Paper]](https://arxiv.org/pdf/2104.02570.pdf)
* Evaluating Multi-label Classifiers with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2102.08427.pdf)
* Self-Supervised Noisy Label Learning for Source-Free Unsupervised Domain Adaptation. [[Paper]](https://arxiv.org/pdf/2102.11614.pdf)
* Transform consistency for learning with noisy labels. [[Paper]](https://arxiv.org/pdf/2103.13872.pdf)
* Learning to Combat Noisy Labels via Classification Margins. [[Paper]](https://arxiv.org/pdf/2102.00751.pdf)
* Joint Negative and Positive Learning for Noisy Labels. [[Paper]](https://arxiv.org/pdf/2104.06574.pdf)
* Robust Classification from Noisy Labels: Integrating Additional Knowledge for Chest
Radiography Abnormality Assessment. [[Paper]](https://arxiv.org/pdf/2104.05261.pdf)
* DST: Data Selection and joint Training for Learning with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.00813.pdf)
* LongReMix: Robust Learning with High Confidence Samples in a Noisy Label Environment. [[Paper]](https://arxiv.org/pdf/2103.04173.pdf)
* A Novel Perspective for Positive-Unlabeled Learning via Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.04685.pdf)
*  Ensemble Learning with Manifold-Based Data Splitting for Noisy Label Correction. [[Paper]](https://arxiv.org/pdf/2103.07641.pdf)
* MetaLabelNet: Learning to Generate Soft-Labels from Noisy-Labels. [[Paper]](https://arxiv.org/pdf/2103.10869.pdf)
* On the Robustness of Monte Carlo Dropout Trained with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.12002.pdf)
*  Co-matching: Combating Noisy Labels by Augmentation Anchoring. [[Paper]](https://arxiv.org/pdf/2103.12814.pdf)
* Pathological Image Segmentation with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2104.02602.pdf)
* CrowdTeacher: Robust Co-teaching with Noisy Answers & Sample-specific Perturbations for Tabular Data. [[Paper]](https://arxiv.org/pdf/2103.17144.pdf)
* Friends and Foes in Learning from Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.15055.pdf)
* Learning from Noisy Labels for Entity-Centric Information Extraction. [[Paper]](https://arxiv.org/pdf/2104.08656.pdf)
* A FRAMEWORK USING CONTRASTIVE LEARNING FOR CLASSIFICATION WITH NOISY LABELS. [[Paper]](https://arxiv.org/pdf/2104.09563.pdf)
* Contrastive Learning Improves Model Robustness Under Label Noise. [[Paper]](https://arxiv.org/pdf/2104.08984.pdf)[[Code]](https://github.com/arghosh/noisy_label_pretrain)
-----
## Papers & Code in 2020
-----
### ICML 2020
* [[**UCSC REAL Lab**]](https://github.com/UCSC-REAL) Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates. [[Paper]](http://proceedings.mlr.press/v119/liu20e)[[Code 1]](https://github.com/weijiaheng/Multi-class-Peer-Loss-functions) [[Code 2]](https://github.com/gohsyi/PeerLoss)
* Normalized Loss Functions for Deep Learning with Noisy Labels. [[Paper]](https://arxiv.org/abs/2006.13554)[[Code]](https://github.com/HanxunH/Active-Passive-Losses)
* SIGUA: Forgetting May Make Learning with Noisy Labels More Robust. [[Paper]](http://proceedings.mlr.press/v119/han20c.html)[[Code]](https://github.com/bhanML/SIGUA)
* Error-Bounded Correction of Noisy Labels. [[Paper]](http://proceedings.mlr.press/v119/zheng20c.html)[[Code]](https://github.com/pingqingsheng/LRT)
* Training Binary Neural Networks through Learning with Noisy Supervision. [[Paper]](http://proceedings.mlr.press/v119/han20d.html)[[Code]](https://github.com/zhaohui-yang/Binary-Neural-Networks)
* Improving generalization by controlling label-noise information in neural network weights. [[Paper]](http://proceedings.mlr.press/v119/harutyunyan20a.html)[[Code]](https://github.com/hrayrhar/limit-label-memorization)
* Self-PU: Self Boosted and Calibrated Positive-Unlabeled Training. [[Paper]](https://arxiv.org/abs/2006.11280)[[Code]](https://github.com/VITA-Group/Self-PU)
* Searching to Exploit Memorization Effect in Learning with Noisy Labels. [[Paper]](http://proceedings.mlr.press/v119/yao20b.html)[[Code]](https://github.com/jerermyyoung/rtlearning)
* Learning with Bounded Instance and Label-dependent Label Noise. [[Paper]](http://proceedings.mlr.press/v119/cheng20c.html)
* Label-Noise Robust Domain Adaptation. [[Paper]](http://proceedings.mlr.press/v119/yu20c.html)
* Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels. [[Paper]](http://proceedings.mlr.press/v119/jiang20c)
* Does label smoothing mitigate label noise?. [[Paper]](http://proceedings.mlr.press/v119/lukasik20a.html)
* Learning with Multiple Complementary Labels. [[Paper]](http://proceedings.mlr.press/v119/feng20a.html)
* Deep k-NN for Noisy Labels. [[Paper]](http://proceedings.mlr.press/v119/bahri20a.html)
* Extreme Multi-label Classification from Aggregated Labels. [[Paper]](http://proceedings.mlr.press/v119/shen20f.html)
-----
### ICLR 2020
* DivideMix: Learning with Noisy Labels as Semi-supervised Learning. [[Paper]](https://openreview.net/forum?id=HJgExaVtwr)[[Code]](https://github.com/LiJunnan1992/DivideMix)
* Learning from Rules Generalizing Labeled Exemplars. [[Paper]](https://openreview.net/pdf?id=SkeuexBtDr) [[Code]](https://github.com/awasthiabhijeet/Learning-From-Rules)
* Robust training with ensemble consensus. [[Paper]](https://openreview.net/forum?id=ryxOUTVYDH)[[Code]](https://github.com/jisoolee0123/Robust-training-with-ensemble-consensus)
* Self-labelling via simultaneous clustering and representation learning. [[Paper]](https://openreview.net/forum?id=Hyx-jyBFPr)[[Code]](https://github.com/yukimasano/self-label)
* Can gradient clipping mitigate label noise? [[Paper]](https://openreview.net/forum?id=rklB76EKPr)[[Code]](https://github.com/dmizr/phuber)
* Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification. [[Paper]](https://openreview.net/forum?id=rJlnOhVYPS)[[Code]](https://github.com/yxgeee/MMT)
* Curriculum Loss: Robust Learning and Generalization against Label Corruption. [[Paper]](https://openreview.net/forum?id=rkgt0REKwS)
* Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee. [[Paper]](https://openreview.net/forum?id=Hke3gyHYwH)
* SELF: Learning to Filter Noisy Labels with Self-Ensembling. [[Paper]](https://openreview.net/forum?id=HkgsPhNYPS)
-----
### Nips 2020
* Part-dependent Label Noise: Towards Instance-dependent Label Noise. [[Paper]](https://papers.nips.cc/paper/2020/hash/5607fe8879e4fd269e88387e8cb30b7e-Abstract.html)[[Code]](https://github.com/xiaoboxia/Part-dependent-label-noise)
* Identifying Mislabeled Data using the Area Under the Margin Ranking. [[Paper]](https://papers.nips.cc/paper/2020/hash/c6102b3727b2a7d8b1bb6981147081ef-Abstract.html)[[Code]](https://github.com/asappresearch/aum)
* Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning. [[Paper]](https://papers.nips.cc/paper/2020/hash/512c5cad6c37edb98ae91c8a76c3a291-Abstract.html)
* Early-Learning Regularization Prevents Memorization of Noisy Labels. [[Paper]](https://papers.nips.cc/paper/2020/hash/ea89621bee7c88b2c5be6681c8ef4906-Abstract.html)[[Code]](https://github.com/shengliu66/ELR)
* Coresets for Robust Training of Deep Neural Networks against Noisy Labels. [[Paper]](https://papers.nips.cc/paper/2020/hash/8493eeaccb772c0878f99d60a0bd2bb3-Abstract.html)[[Code]](https://github.com/snap-stanford/crust)
* Modeling Noisy Annotations for Crowd Counting. [[Paper]](https://papers.nips.cc/paper/2020/hash/22bb543b251c39ccdad8063d486987bb-Abstract.html)[[Code]](https://github.com/jia-wan/NoisyCC-pytorch)
* Robust Optimization for Fairness with Noisy Protected Groups. [[Paper]](https://papers.nips.cc/paper/2020/hash/37d097caf1299d9aa79c2c2b843d2d78-Abstract.html)[[Code]](https://github.com/wenshuoguo/robust-fairness-code)
* Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient Clipping. [[Paper]](https://papers.nips.cc/paper/2020/hash/abd1c782880cc59759f4112fda0b8f98-Abstract.html)[[Code]](https://github.com/eduardgorbunov/accelerated_clipping)
* A Topological Filter for Learning with Label Noise. [[Paper]](https://papers.nips.cc/paper/2020/hash/f4e3ce3e7b581ff32e40968298ba013d-Abstract.html)[[Code]](https://github.com/pxiangwu/TopoFilter)
* Self-Adaptive Training: beyond Empirical Risk Minimization. [[Paper]](https://proceedings.neurips.cc//paper/2020/hash/e0ab531ec312161511493b002f9be2ee-Abstract.html)[[Code]](https://github.com/LayneH/self-adaptive-training)
* Disentangling Human Error from the Ground Truth in Segmentation of Medical Images. [[Paper]](https://proceedings.neurips.cc//paper/2020/file/b5d17ed2b502da15aa727af0d51508d6-Paper.pdf)[[Code]](https://github.com/moucheng2017/Learn_Noisy_Labels_Medical_Images)
* Non-Convex SGD Learns Halfspaces with Adversarial Label Noise. [[Paper]](https://papers.nips.cc/paper/2020/hash/d785bf9067f8af9e078b93cf26de2b54-Abstract.html)
* Efficient active learning of sparse halfspaces with arbitrary bounded noise. [[Paper]](https://papers.nips.cc/paper/2020/hash/5034a5d62f91942d2a7aeaf527dfe111-Abstract.html)
* Semi-Supervised Partial Label Learning via Confidence-Rated Margin Maximization. [[Paper]](https://papers.nips.cc/paper/2020/hash/4dea382d82666332fb564f2e711cbc71-Abstract.html)
* Labelling unlabelled videos from scratch with multi-modal self-supervision. [[Paper]](https://papers.nips.cc/paper/2020/hash/31fefc0e570cb3860f2a6d4b38c6490d-Abstract.html)[[Code]](https://github.com/facebookresearch/selavi)
* Distribution Aligning Refinery of Pseudo-label for Imbalanced Semi-supervised Learning. [[Paper]](https://papers.nips.cc/paper/2020/hash/a7968b4339a1b85b7dbdb362dc44f9c4-Abstract.html)[[Code]](https://github.com/bbuing9/DARP)
* MetaPoison: Practical General-purpose Clean-label Data Poisoning. [[Paper]](https://papers.nips.cc/paper/2020/hash/8ce6fc704072e351679ac97d4a985574-Abstract.html)[[Code 1]](https://github.com/wronnyhuang/metapoison)[[Code 2]](https://github.com/JonasGeiping/poisoning-gradient-matching)
* Provably Consistent Partial-Label Learning. [[Paper]](https://papers.nips.cc/paper/2020/hash/7bd28f15a49d5e5848d6ec70e584e625-Abstract.html)
* A Variational Approach for Learning from Positive and Unlabeled Data. [[Paper]](https://papers.nips.cc/paper/2020/hash/aa0d2a804a3510442f2fd40f2100b054-Abstract.html)[[Code]](https://github.com/HC-Feynman/vpu)
-----
### AAAI 2020
* [[**UCSC REAL Lab**]](https://github.com/UCSC-REAL) Reinforcement Learning with Perturbed Rewards. [[Paper]](https://arxiv.org/abs/1810.01032) [[Code]](https://github.com/wangjksjtu/rl-perturbed-reward)
* Less Is Better: Unweighted Data Subsampling via Influence Function. [[Paper]](https://arxiv.org/abs/1912.01321) [[Code]](https://github.com/RyanWangZf/Influence_Subsampling)
* Weakly Supervised Sequence Tagging from Noisy Rules. [[Paper]](https://ojs.aaai.org//index.php/AAAI/article/view/6009)[[Code]](https://github.com/BatsResearch/wiser)
* Coupled-View Deep Classifier Learning from Multiple Noisy Annotators. [[Paper]](https://ojs.aaai.org//index.php/AAAI/article/view/5898)
* Partial multi-label learning with noisy label identification. [[Paper]](http://www.xiemk.pro/publication/aaai20-pml-ni.pdf)
* Self-Paced Robust Learning for Leveraging Clean Labels in Noisy Data. [[Paper]](https://xuczhang.github.io/papers/aaai20_sprl.pdf)
* Label Error Correction and Generation Through Label Relationships. [[Paper]](https://ojs.aaai.org//index.php/AAAI/article/view/5778)
-----
### CVPR 2020
* Combating noisy labels by agreement: A joint training method with co-regularization. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/html/Wei_Combating_Noisy_Labels_by_Agreement_A_Joint_Training_Method_with_CVPR_2020_paper.html)[[Code]](https://github.com/hongxin001/JoCoR)
* Distilling Effective Supervision From Severe Label Noise. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/html/Zhang_Distilling_Effective_Supervision_From_Severe_Label_Noise_CVPR_2020_paper.html)[[Code]](https://github.com/google-research/google-research/tree/master/ieg)
* Self-Training With Noisy Student Improves ImageNet Classification. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/html/Xie_Self-Training_With_Noisy_Student_Improves_ImageNet_Classification_CVPR_2020_paper.html)[[Code]](https://github.com/google-research/noisystudent)
* Noise Robust Generative Adversarial Networks. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/html/Kaneko_Noise_Robust_Generative_Adversarial_Networks_CVPR_2020_paper.html)[[Code]](https://github.com/takuhirok/NR-GAN/)
* Global-Local GCN: Large-Scale Label Noise Cleansing for Face Recognition. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/html/Zhang_Global-Local_GCN_Large-Scale_Label_Noise_Cleansing_for_Face_Recognition_CVPR_2020_paper.html)
* DLWL: Improving Detection for Lowshot Classes With Weakly Labelled Data. [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Ramanathan_DLWL_Improving_Detection_for_Lowshot_Classes_With_Weakly_Labelled_Data_CVPR_2020_paper.html)
* Spherical Space Domain Adaptation With Robust Pseudo-Label Loss. [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Gu_Spherical_Space_Domain_Adaptation_With_Robust_Pseudo-Label_Loss_CVPR_2020_paper.html)[[Code]](https://github.com/XJTU-XGU/RSDA)
* Training Noise-Robust Deep Neural Networks via Meta-Learning. [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_Training_Noise-Robust_Deep_Neural_Networks_via_Meta-Learning_CVPR_2020_paper.html)[[Code]](https://github.com/ZhenWang-PhD/Training-Noise-Robust-Deep-Neural-Networks-via-Meta-Learning)
* Shoestring: Graph-Based Semi-Supervised Classification With Severely Limited Labeled Data. [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Lin_Shoestring_Graph-Based_Semi-Supervised_Classification_With_Severely_Limited_Labeled_Data_CVPR_2020_paper.html)[[Code]](https://github.com/iQua/CVPR2020-Shoestring)
* Noise-Aware Fully Webly Supervised Object Detection. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/html/Shen_Noise-Aware_Fully_Webly_Supervised_Object_Detection_CVPR_2020_paper.html)[[Code]](https://github.com/shenyunhang/NA-fWebSOD)
* Learning From Noisy Anchors for One-Stage Object Detection. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/html/Li_Learning_From_Noisy_Anchors_for_One-Stage_Object_Detection_CVPR_2020_paper.html)[[Code]](https://github.com/henrylee2570/NoisyAnchor)
* Generating Accurate Pseudo-Labels in Semi-Supervised Learning and Avoiding Overconfident Predictions via Hermite Polynomial Activations. [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Lokhande_Generating_Accurate_Pseudo-Labels_in_Semi-Supervised_Learning_and_Avoiding_Overconfident_Predictions_CVPR_2020_paper.html)[[Code]](https://github.com/lokhande-vishnu/DeepHermites)
* Revisiting Knowledge Distillation via Label Smoothing Regularization. [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Yuan_Revisiting_Knowledge_Distillation_via_Label_Smoothing_Regularization_CVPR_2020_paper.html)[[Code]](https://github.com/yuanli2333/Teacher-free-Knowledge-Distillation)
-----
### ECCV 2020
* 2020-ECCV - Learning with Noisy Class Labels for Instance Segmentation. [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/2062_ECCV_2020_paper.php)[[Code]](https://github.com/longrongyang/LNCIS)
* 2020-ECCV - Suppressing Mislabeled Data via Grouping and Self-Attention. [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/2633_ECCV_2020_paper.php)[[Code]](https://github.com/kaiwang960112/AFM)
* 2020-ECCV - NoiseRank: Unsupervised Label Noise Reduction with Dependence Models. [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/5921_ECCV_2020_paper.php)
* 2020-ECCV - Weakly Supervised Learning with Side Information for Noisy Labeled Images. [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/7467_ECCV_2020_paper.php)
* 2020-ECCV - Learning Noise-Aware Encoder-Decoder from Noisy Labels by Alternating Back-Propagation for Saliency Detection. [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/2760_ECCV_2020_paper.php)
* 2020-ECCV - Graph convolutional networks for learning with few clean and many noisy labels. [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/1060_ECCV_2020_paper.php)
-----
### ArXiv 2020
* No Regret Sample Selection with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2003.03179.pdf)[[Code]](https://github.com/songheony/TAkS)
* Meta Soft Label Generation for Noisy Labels. [[Paper]](https://arxiv.org/pdf/2007.05836.pdf)[[Code]](https://github.com/gorkemalgan/MSLG_noisy_label)
* Learning from Noisy Labels with Deep Neural Networks: A Survey. [[Paper]](https://arxiv.org/pdf/2007.08199.pdf)
* RAR-U-Net: a Residual Encoder to Attention Decoder by Residual Connections Framework for Spine Segmentation under Noisy Labels. [[Paper]](https://arxiv.org/pdf/2009.12873.pdf)
* Learning from Small Amount of Medical Data with Noisy Labels: A Meta-Learning Approach. [[Paper]](https://arxiv.org/pdf/2010.06939.pdf)
-----
